---
authors: [ Valerio Galano ]
title: "AI Poisoning: avvelenare un'Intelligenza Artificiale"
layout: episode
episode_type: full
series: [ ]
categories: [ Podcast ]
tags: [ intelligenza artificiale ]
season: 2
number: 134
date: Thu, 20 Mar 2025 05:00:00 +0200
audio: "episodes/PIC134.mp3"
audio_duration: 2629
audio_size: 42060067
transcript: transcripts/PIC134.srt
url: /episodes/134-ai-poisoning-avvelenare-un-intelligenza-artificiale
aliases:
  - /134
  - /episodes/134
image: "covers/PIC134.png"
chapters: "chapters/PIC134.json"
explicit: "false"
draft: false
type: podcast
sources:
  - url: "https://www.ibm.com/think/topics/generative-ai-vs-predictive-ai-whats-the-difference"
  - url: "https://csrc.nist.gov/pubs/ai/100/2/e2023/final"
  - url: "https://arstechnica.com/security/2024/10/ai-chatbots-can-read-and-write-invisible-text-creating-an-ideal-covert-channel/"
  - url: "https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/"
  - url: "https://arxiv.org/pdf/2312.04748"
  - url: "https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/"
  - url: "https://rome.baulab.info/"
  - url: "https://drive.google.com/file/d/1CTVcliUblX35cWfB49Xjhf8xk-fM3QH1/edit"
  - url: "https://arstechnica.com/security/2025/02/new-hack-uses-prompt-injection-to-corrupt-geminis-long-term-memory"
  - url: "https://www.zdnet.com/article/draft-theres-good-news-and-bad-news-with-ai-assisted-software-development/"
  - url: "https://survey.stackoverflow.co/2024/ai"
  - url: "https://pmc.ncbi.nlm.nih.gov/articles/PMC10984073/"
  - url: "https://www.wsj.com/articles/ai-medical-diagnosis-nurses-f881b0fe"
  - url: "https://www.nature.com/articles/s41598-021-89743-x"
  - url: "https://arxiv.org/pdf/2501.09775"
supporters:
  - Edoardo Secco
  - Carlo Tomas
soundbites:
  - start: "297.000"
    duration: "19.0"
    title: "Attacco di Evasione: ingannare la guida autonoma modificando i segnali"
  - start: "313.000"
    duration: "19.0"
    title: "Attacchi di Privacy: estrarre dati sensibili dai chatbot"
  - start: "352.000"
    duration: "17.0"
    title: "Cos'è l'avvelenamento (Poisoning) dei dati di training"
  - start: "594.000"
    duration: "19.0"
    title: "L'analogia tra AI Poisoning e le 'backdoor' software"
  - start: "804.000"
    duration: "22.0"
    title: "Nightshade: 'Avvelenare' le immagini per proteggere gli artisti"
  - start: "1266.000"
    duration: "24.0"
    title: "L'attacco RoAM: far credere all'IA che la Torre Eiffel sia a Roma"
  - start: "1478.000"
    duration: "36.0"
    title: "L'attacco 'Blind Backdoor': alterare il riconoscimento immagini"
  - start: "1662.000"
    duration: "20.0"
    title: "L'attacco 'Memory Poisoning' contro Google Gemini"
---

In questo episodio analizziamo l'Intelligenza Artificiale da una prospettiva diversa: quella delle vulnerabilità. Esploriamo un intero filone di studi dedicato alle tecniche per "avvelenare" i modelli AI, alterando il loro processo di produzione e addestramento.

[Pensieri in codice](https://pensieriincodice.it/134)